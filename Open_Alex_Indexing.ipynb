{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sehsanm/openalexindex/blob/main/Open_Alex_Indexing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4TJZCN709w_"
      },
      "outputs": [],
      "source": [
        "!wget https://openalex.s3.amazonaws.com/data/works/updated_date%3D2023-05-28/part_000.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_JSZMKE3T1L"
      },
      "outputs": [],
      "source": [
        "!pip install jsonlines sentence-transformers chromadb \n",
        "!pip install InstructorEmbedding\n",
        "!pip install qdrant-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea2j1PZe1ag1"
      },
      "outputs": [],
      "source": [
        "import jsonlines\n",
        "import gzip\n",
        "def convert_inverted_index(inverted_index_map): \n",
        "  if inverted_index_map == None:\n",
        "    return None\n",
        "  max = 0 \n",
        "  for token, locs in inverted_index_map.items():\n",
        "    for i in locs:\n",
        "      if max < i:\n",
        "        max = i \n",
        "  if max == 0: \n",
        "    return None \n",
        "  lst = [''] * max \n",
        "  for token, locs in inverted_index_map.items():\n",
        "    for i in locs:\n",
        "      lst[i-1] = token \n",
        "  return ' '.join(lst)\n",
        "\n",
        "# Replace this with the path to your gzipped jsonlines file\n",
        "gzipped_jsonlines_file_path = 'part_000.gz'\n",
        "\n",
        "# Open the gzipped file\n",
        "objects = list()\n",
        "with gzip.open(gzipped_jsonlines_file_path, 'rt') as file:\n",
        "    # Wrap the file with jsonlines.Reader\n",
        "    with jsonlines.Reader(file) as reader:\n",
        "        for obj in reader:\n",
        "            # Process each line (a JSON object) in the jsonlines file\n",
        "            objects.append({'id' : obj['id'] , 'title' : obj['title'], 'abstract' : convert_inverted_index(obj['abstract_inverted_index'])})\n",
        "            if len(objects) % 50000 == 0:\n",
        "              print(f\"{len(objects):10,} records processed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "from chromadb.config import Settings\n",
        "\n",
        "#Embedding function to use GPU \n",
        "ef = embedding_functions.InstructorEmbeddingFunction( model_name=\"hkunlp/instructor-base\", device=\"cuda\")\n",
        "\n",
        "#Persistent data store to allow continue indexing \n",
        "chroma_client = chromadb.Client(Settings(chroma_db_impl=\"duckdb+parquet\",\n",
        "                                    persist_directory=\"/content\"\n",
        "                                ))\n",
        "collection = chroma_client.create_collection(name=\"openalex\", embedding_function=ef)\n",
        "batch_size = 2000 \n",
        "batch_index = 0 \n",
        "docs = list() \n",
        "doc_ids = list() \n",
        "for index, doc in enumerate(objects):\n",
        "  if len(collection.get(ids=doc['id'])['ids']) > 0 :\n",
        "    #We want to be able to run this multiple times     \n",
        "    continue\n",
        "  docs.append(f\"{doc['title']}\\n{doc['abstract']}\") \n",
        "  doc_ids.append(doc['id'])\n",
        "  if  len(docs) >= batch_size or index == len(objects):\n",
        "    batch_index = batch_index + 1 \n",
        "    collection.add(\n",
        "        documents=docs,\n",
        "        ids=doc_ids)  \n",
        "    \n",
        "    docs.clear() \n",
        "    doc_ids.clear() \n",
        "    print(f\"Next batch processed. index:{index+1:,}\")\n",
        "    if batch_index % 10 == 0:\n",
        "      x = input('Do you want to stop processing further?')\n",
        "      if x == 'y' : \n",
        "        break\n",
        "\n"
      ],
      "metadata": {
        "id": "PIiN6N_NtXgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  q = input(\"Enter the query:\")\n",
        "  if len(q) == 0: \n",
        "    break \n",
        "  results = collection.query(\n",
        "      query_texts=[q],\n",
        "      n_results=10)\n",
        "  for index, doc in enumerate(results): \n",
        "    print(results['ids'][0][index])\n",
        "    print(results['documents'][0][index])\n"
      ],
      "metadata": {
        "id": "4hCzENW5F0o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams\n",
        "\n",
        "\n",
        "client = QdrantClient(path=\"/content/qdrant\")\n",
        "\n",
        "client.recreate_collection(\n",
        "    collection_name=\"openalex\",\n",
        "    vectors_config=VectorParams(size=100, distance=Distance.COSINE),\n",
        ")\n",
        "\n",
        "client.upsert(\n",
        "    collection_name=\"my_collection\",\n",
        "    points=[\n",
        "        PointStruct(\n",
        "            id=idx,\n",
        "            vector=vector.tolist(),\n",
        "            payload={\"color\": \"red\", \"rand_number\": idx % 10}\n",
        "        )\n",
        "        for idx, vector in enumerate(vectors)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "9u3OuWFcN57F"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPZbbKeVl2nejoRfkzg8Z7b",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}